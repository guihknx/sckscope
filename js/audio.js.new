// create the audio context (chrome only for now)
// The name of this file is ambiguous until there's a standard audio context.
// Original code from: http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound
WebkitAudioContext = function () {
  var context = new webkitAudioContext();
  var audioBuffer, sourceNode = {
      buffer: 0
    }, splitter, analyser, analyser2, javascriptNode, channels, note, audioUrl;
  // load the sound
  setupAudioNodes();
  //loadSound(audio);

  function setupAudioNodes() {

    // setup a javascript node
    javascriptNode = context.createJavaScriptNode(2048, 1, 1);
    // connect to destination, else it isn't called
    javascriptNode.connect(context.destination);


    // setup a analyzer
    analyser = context.createAnalyser();
    analyser.smoothingTimeConstant = 0.3;
    analyser.fftSize = 1024;

    analyser2 = context.createAnalyser();
    analyser2.smoothingTimeConstant = 0.0;
    analyser2.fftSize = 1024;

    // create a buffer source node
    sourceNode = context.createBufferSource();
    splitter = context.createChannelSplitter();

    // connect the source to the analyser and the splitter
    sourceNode.connect(splitter);

    // connect one of the outputs from the splitter to
    // the analyser
    splitter.connect(analyser, 0, 0);
    splitter.connect(analyser2, 1, 0);

    // connect the splitter to the javascriptnode
    // we use the javascript node to draw at a
    // specific interval.
    analyser.connect(javascriptNode);

    //        splitter.connect(context.destination,0,0);
    //        splitter.connect(context.destination,0,1);

    // and connect to destination
    sourceNode.connect(context.destination);
    
    channels = {
      analyser: analyser,
      analyser2: analyser2
    }
  }
  
  // load the specified sound
  function loadSound(url) {
    audioUrl = url;
    var request = new XMLHttpRequest();
    request.open('GET', url, true);
    request.responseType = 'arraybuffer';
    // When loaded decode the data
    request.onload = function () {
      // decode the data
      context.decodeAudioData(request.response, function (buffer) {
        // when the audio is decoded play the sound
        //playSound(buffer, 0);
        sourceNode.buffer = buffer;
        console.log(sourceNode.buffer);
        console.log('decoded url');
      }, onError);
    }
    
    request.send();
    return true;
  }


  function playSound(start, url, dur) {
    if(start == 0){
      loadSound(url);
      sourceNode.start(0);
    } else {
      loadSound(url);
      console.log(sourceNode);
      console.log('reloading url');
      sourceNode.start(0, 20, 102.16595833333334);
      //sourceNode.start(0);
    }
  }

  function stopSound() {
    sourceNode.stop(0);
    this.currentTime = context.currentTime;
    javascriptNode.disconnect();
    sourceNode.disconnect();
  }

  // log if an error occurs

  function onError(e) {
    console.log(e);
  }

  this.getAverageVolume = function (array) {
    var values = 0;
    var average;

    var length = array.length;

    // get all the frequency amplitudes
    for (var i = 0; i < length; i++) {
      values += array[i];
    }
    average = values / length;
    return average;
  }
  
  this.currentTime = function(){
    return context.currentTime;
  }
  this.javascriptNode = javascriptNode;
  this.loadSound = function (audio) {
    loadSound(audio);
  }
  this.stopSound = function (current) {
    stopSound();
  }
  this.playSound = function (currentTime, url, dur) {
    playSound(currentTime, url, dur);
  }
  this.ch = channels;
}